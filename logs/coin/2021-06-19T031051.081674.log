2021-06-19 03:10:52 [scrapy] DEBUG: Crawled (200) <GET https://coinmarketcap.com/robots.txt> (referer: None)
2021-06-19 03:10:53 [scrapy] DEBUG: Crawled (200) <GET https://coinmarketcap.com/> (referer: None)
2021-06-19 03:10:53 [scrapy] ERROR: Error processing {'marketcap': ['$666,138,072,655',
               '$257,555,065,693',
               '$62,665,985,474',
               '$51,344,090,441',
               '$45,020,269,919',
               '$38,171,278,165',
               '$36,594,686,229',
               '$24,198,968,502',
               '$20,228,815,825',
               '$11,662,881,102'],
 'name': ['Bitcoin',
          'Ethereum',
          'Tether',
          'Binance Coin',
          'Cardano',
          'Dogecoin',
          'XRP',
          'USD Coin',
          'Polkadot',
          'Uniswap'],
 'volume': ['$35,902,087,385',
            '$22,730,255,896',
            '$58,199,716,870',
            '$1,597,407,388',
            '$2,107,320,533',
            '$1,843,954,656',
            '$2,529,120,033',
            '$2,052,412,590',
            '$1,396,077,665',
            '$351,622,601']}
Traceback (most recent call last):
  File "c:\users\asus\anaconda3\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\asus\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "C:\Users\Asus\Desktop\RCDAT\qu\quote\quote\pipelines.py", line 31, in process_item
    self.store_db(items)
  File "C:\Users\Asus\Desktop\RCDAT\qu\quote\quote\pipelines.py", line 36, in store_db
    self.curr("""insert into coins_tb values (?,?,?) """,(
TypeError: 'sqlite3.Cursor' object is not callable
2021-06-19 03:10:53 [scrapy] INFO: Closing spider (finished)
2021-06-19 03:10:53 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 452,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 83615,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 2.373786,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 6, 18, 22, 40, 53, 501695),
 'httpcompression/response_bytes': 636302,
 'httpcompression/response_count': 2,
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2021, 6, 18, 22, 40, 51, 127909)}
2021-06-19 03:10:53 [scrapy] INFO: Spider closed (finished)
